{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Long Term Averages'),\n",
    "                ('abstract', 'Long term averages of aggregated vegetation indicators, aggregated LST and rainfall estimates'),\n",
    "                ('id', 'wfp-01-03-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_product = dict([('id', 'oe_product'),\n",
    "                   ('value', 'CHIRPSv2'),\n",
    "                   ('title', 'CHIRPSv2, LAI or FAPAR'),\n",
    "                   ('abstract', 'CHIRPSv2, LAI or FAPAR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = dict([('id', 'startdate'),\n",
    "                  ('value', '2014-01-01T00:00Z'),\n",
    "                  ('title', 'Start date'),\n",
    "                  ('abstract', 'Start date')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddate = dict([('id', 'enddate'),\n",
    "                ('value', '2018-01-01T00:00Z'),\n",
    "                ('title', 'End date'),\n",
    "                ('abstract', 'End date')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = dict([('id', 'update'),\n",
    "               ('value', '2020-06-01T00:00Z/2020-06-11T00:00Z'),\n",
    "               ('title', 'update'),\n",
    "               ('abstract', 'update')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue_url = dict([('id', 'catalogue_url'),\n",
    "                      ('value', 'https://catalog.terradue.com/better-wfp-00007/search'),\n",
    "                      ('title', 'catalogue url'),\n",
    "                      ('abstract', 'catalogue url')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "param": "aoi"
   },
   "outputs": [],
   "source": [
    "# chirps\n",
    "input_references = ['https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=D439CE02D08C17357E7F74AE4F705B1AA8B36ED4',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=D802F6B72172CDA321D72900A7CEF999A4425D6F',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=07F4BDE764FFC44A383C456544E254509FC71240',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=449AC1A215D5808A38C276067214069E7B098984',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=B1BDEC2E01B64B1E1F66DE76E45EAC3EC3ADB0B7',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=4CE22627C6210612F47B7EF696AE0F58E50DB966',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=9DC33D4A6F0C56BCED43A69C863C0CAB3FF215C4',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=07E4EE4D7B7969C7EC7E49AFDE6D7C2E8FF7E060',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=5DA7E0E6B4639993E30E96FC0F91E3227CDC2510',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=7FF175AEA419219213F7A0FE744E665205B90075',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=B251E2E5E19E7F408CA3556C80A0F2FF51F97A64',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=44B0123B0518B335A0EAD40AFF753C41C66B7FA1',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=2F0061E6315C54E1FA569C20CE337917A33BBE31',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=17E7E24A8B0632E6C65560CE1630A2DB91EE2466',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=AEBF293831A874781E68687E1B96747AA8CEF2A2',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=2EBE0ABE04CBE6B780276983CB060928CA7299DF',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=4A7721E122974D16ECFDC91F195944F9FF6DF2DE',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=BEAFDC105C63BFF667CFFFCC759C6FD1BCA0F7EE',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=BF4A447F6D0CF6E60EB74DDB86140EC6C4CC9238',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=F5E80E0FEC4FFC22EC940D37DCDE5EAA50FDC25C',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=CF9023C1EB011513A02DA689C12BA7EB479B6210',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=FB5FCBE5C6BD5A98081B1F20FE58D8E2B05021E9',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=F0BAF9029BCAE2BAE1C518FBC0743B88FFCBB08B',\n",
    "                    'https://catalog.terradue.com/better-wfp-00007/search?format=atom&uid=0E731F7CCFA4794AD9CD6CDCB5448A1CD9A6F3B9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import gzip\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import cioppy\n",
    "import requests\n",
    "\n",
    "sys.path.append('/application/notebook/libexec')\n",
    "sys.path.append('/workspace/wfp-01-03-04/src/main/app-resources/notebook/libexec')\n",
    "from aux_functions import calc_average, matrix_sum, write_output_image, get_matrix_list\n",
    "\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(row):\n",
    "    search = ciop.search(end_point=row['catalogue_url'], \n",
    "                                  params=[],\n",
    "                                  output_fields='self,enclosure,startdate,enddate,wkt,updated,title',\n",
    "                                  model='GeoTime')[0]\n",
    "    \n",
    "    series = pd.Series(search)\n",
    "    \n",
    "    series['startdate'] = pd.to_datetime(series['startdate'])\n",
    "    series['enddate'] = pd.to_datetime(series['enddate'])\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product(url, dest):\n",
    "    \n",
    "    #request_headers = {'X-JFrog-Art-Api': api_key}\n",
    "\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    open(dest, 'wb').write(r.content)\n",
    "    \n",
    "    return r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_date(product_reference):\n",
    "    metadata = ciop.search(end_point=product_reference,\n",
    "                           params=[],\n",
    "                           output_fields='identifier,startdate,enddate',\n",
    "                           model=\"GeoTime\")\n",
    "    return metadata[0]['startdate'], metadata[0]['enddate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_match_duplicates(gdf_match):\n",
    "    years = gdf_match['startdate'].dt.year.unique()\n",
    "    for year in years:\n",
    "        products = gdf_match[gdf_match['startdate'].dt.year == year]\n",
    "        if len(products.index.values) > 1:\n",
    "            outdated_indexes = products[products['updated'] != max(products['updated'])].index.values\n",
    "            gdf_match = gdf_match.drop(outdated_indexes)\n",
    "    return gdf_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_properties_file(dataframe, output_name):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    first_date = get_formatted_date(dataframe.iloc[0]['self'])[0]\n",
    "    last_date = get_formatted_date(dataframe.iloc[-1]['self'])[1]\n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (dataframe.iloc[0]['wkt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lta(dataframe):\n",
    "    \n",
    "    file_list = []\n",
    "    \n",
    "    for enclosure in dataframe['enclosure'].tolist():\n",
    "        filepath = os.path.join('tmp_data', os.path.basename(enclosure))\n",
    "        status = get_product(enclosure, filepath)\n",
    "        #status = 200 # TEMP\n",
    "        if status == 200:\n",
    "            file_list.append(filepath)\n",
    "    print(file_list)\n",
    "    \n",
    "    if file_list:\n",
    "        n_years = len(file_list)\n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        print('Aggregations converted to matrices')\n",
    "        lta = calc_average(agr_period_matrix, n_years)\n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        for file_ in file_list:\n",
    "            os.remove(file_)\n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(lta, period_start_date, period_end_date, product_type, period_N, agr_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    start_day_month = str(period_start_date.month) + '-' + str(period_start_date.day)\n",
    "    end_day_month = str(period_end_date.month) + '-' + str(period_end_date.day)\n",
    "    output_name = 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + start_day_month + '_' + end_day_month + '_' + str(period_start_date.year) + '_' + str(period_end_date.year) + '.tif'\n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_chirps(lta, period_start_date, period_end_date, product_type, period_N, agr_type, region, dekad_flag, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    \n",
    "    end_day_month = '{0:02}'.format(period_end_date.month) + '-' + dekad_flag\n",
    "    \n",
    "    output_name = 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + end_day_month + '_' + str(period_start_date.year) + '_' + str(period_end_date.year) + '.tif'\n",
    "    \n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    \n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('tmp_data'):\n",
    "    os.mkdir('tmp_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(input_references, str):\n",
    "    input_references = [input_references]\n",
    "\n",
    "gpd_data = pd.DataFrame(input_references, columns=['catalogue_url'])\n",
    "#gpd_data = GeoDataFrame(columns=['enclosure', 'start_date', 'end_date', 'product_type', 'aggregation', 'region'])\n",
    "gpd_data = gpd_data.apply(lambda row: get_info(row), axis=1)\n",
    "\n",
    "\n",
    "'''for i, enc in enumerate(gpd_data['enclosure'].tolist()):\n",
    "    print(i)\n",
    "    print(enc)\n",
    "    filename = os.path.splitext(os.path.basename(enc))[0]\n",
    "    file_comp = filename.split('_')\n",
    "    start_date = file_comp[-2]\n",
    "    end_date = file_comp[-1]\n",
    "    product_type = file_comp[0]\n",
    "    region = file_comp[1]\n",
    "    aggregation = file_comp[3]'''\n",
    "\n",
    "gpd_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_data = gpd_data.sort_values(by='enddate')\n",
    "gpd_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if oe_product['value'] == 'FAPAR' or oe_product['value'] == 'LAI':\n",
    "    \n",
    "    while not gpd_data.empty:\n",
    "        \n",
    "        # gets first product\n",
    "        l1 = gpd_data.iloc[0]\n",
    "        filename = os.path.splitext(os.path.basename(l1['enclosure']))[0].split('_')\n",
    "    \n",
    "        agr = filename[3]\n",
    "        prod_type = filename[0]\n",
    "        N_value = filename[2]\n",
    "        region = filename[1]\n",
    "    \n",
    "        #\n",
    "        # match those with same start day, start month, end day, end month, wkt, agr (avrg, daytotal), product type (chirps,fapar)\n",
    "        #\n",
    "        match = gpd_data[(gpd_data['startdate'].dt.day == l1['startdate'].day) & \n",
    "                         (gpd_data['startdate'].dt.month == l1['startdate'].month) & \n",
    "                         (gpd_data['enddate'].dt.day == l1['enddate'].day) & \n",
    "                         (gpd_data['enddate'].dt.month == l1['enddate'].month) &\n",
    "                         (gpd_data['wkt'] == l1['wkt']) &\n",
    "                         (gpd_data['enclosure'].str.contains(agr)) &\n",
    "                         (gpd_data['enclosure'].str.contains(prod_type))]\n",
    "    \n",
    "        indexes = match.index.values\n",
    "    \n",
    "        if len(indexes) > 1:\n",
    "        \n",
    "            print(len(match.index.values))\n",
    "            match = remove_match_duplicates(match)\n",
    "            print(len(match.index.values))\n",
    "            lta, projection, geo_transform, no_data_value, data_type = calc_lta(match)\n",
    "            if lta is not None:\n",
    "                filename = write_output(lta, match.iloc[0]['startdate'], match.iloc[-1]['enddate'], prod_type, N_value, agr, region, projection, geo_transform, 'GTiff', no_data_value, data_type)\n",
    "                print(filename)\n",
    "                write_properties_file(match, filename)\n",
    "            \n",
    "        gpd_data = gpd_data.drop(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if oe_product['value'] == 'CHIRPSv2':\n",
    "    \n",
    "    while not gpd_data.empty:\n",
    "        \n",
    "        # gets first product\n",
    "        l1 = gpd_data.iloc[0]\n",
    "        #filename = os.path.splitext(os.path.basename(l1['enclosure']))[0].split('_')\n",
    "    \n",
    "        filename = os.path.basename(l1['enclosure']).split('_')\n",
    "    \n",
    "        agr = filename[3]\n",
    "        prod_type = filename[0]\n",
    "        N_value = filename[2]\n",
    "        region = filename[1]\n",
    "        \n",
    "        str_date = filename[4]\n",
    "        \n",
    "        dekad_flag = str_date.split('-')[-1]\n",
    "    \n",
    "        #\n",
    "        # match those with same start day, start month, end day, end month, wkt, agr (avrg, daytotal), product type (chirps,fapar)\n",
    "        #\n",
    "        match = gpd_data[(gpd_data['enddate'].dt.month == l1['enddate'].month) &\n",
    "                         (gpd_data['wkt'] == l1['wkt']) &\n",
    "                         (gpd_data['enclosure'].str.contains('_' + agr + '_')) &\n",
    "                         (gpd_data['enclosure'].str.contains('_' + N_value + '_')) &\n",
    "                         (gpd_data['enclosure'].str.contains(prod_type)) &\n",
    "                         (gpd_data['enclosure'].str.contains(dekad_flag))]\n",
    "        \n",
    "    \n",
    "        indexes = match.index.values\n",
    "    \n",
    "        if len(indexes) > 1:\n",
    "        \n",
    "            print('match att:')\n",
    "            print(l1['enddate'].month, '_' + agr + '_', '_' + N_value + '_', prod_type, dekad_flag)\n",
    "            \n",
    "            print(len(match.index.values))\n",
    "            #match = remove_match_duplicates(match)\n",
    "            #print(len(match.index.values))\n",
    "            lta, projection, geo_transform, no_data_value, data_type = calc_lta(match)\n",
    "            if lta is not None:\n",
    "                dekad_flag = dekad_flag.split('.')[0] # remove .tif\n",
    "                filename = write_output_chirps(lta, match.iloc[0]['startdate'], match.iloc[-1]['enddate'], prod_type, N_value, agr, region, dekad_flag, projection, geo_transform, 'GTiff', no_data_value, data_type)\n",
    "                print(filename)\n",
    "                write_properties_file(match, filename)\n",
    "            \n",
    "        gpd_data = gpd_data.drop(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('tmp_data')\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % ('tmp_data', e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ewf-wfp-01-03-04",
   "language": "python",
   "name": "env_ewf-wfp-01-03-04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
