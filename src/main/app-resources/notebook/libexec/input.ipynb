{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Long Term Averages'),\n",
    "                ('abstract', 'Long term averages of aggregated vegetation indicators, aggregated LST and rainfall estimates'),\n",
    "                ('id', 'wfp-01-03-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "param": "aoi"
   },
   "outputs": [],
   "source": [
    "input_references = 'https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=08895f9204851c5ae137d2c6408aa31184fc2b46'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=08895f9204851c5ae137d2c6408aa31184fc2b46\n"
     ]
    }
   ],
   "source": [
    "print(input_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from geopandas import GeoDataFrame\n",
    "import gzip\n",
    "import cioppy\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import cioppy\n",
    "import requests\n",
    "sys.path.append('/application/notebook/libexec')\n",
    "sys.path.append('/workspace/wfp-01-03-04/src/main/app-resources/notebook/libexec')\n",
    "from aux_functions import calc_average, matrix_sum, write_output_image, get_matrix_list\n",
    "\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''input_references = [\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=47C7A040807147E314B879FEF177D236C47C41CF\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=489368F5FC2DDF9FB23436FD21D44594A117D4F3\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=84A1AA9FA70039F4C5C90B2245FDB69A66054C20\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=7C4002FF16878FEABFEAFF2F75150DEC008A483A\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=94EF932B5FF714852A4A5A6461CF06B20B1F1113\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=AA2E4B4742372B08271EC265D19536705972F771\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=48230F129D42083F75AD47BB35812899C91C28DF\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=554265DA1B10BB2F97520C3AD3BCCC2C3151F965\",\n",
    "\"https://catalog.terradue.com//better-wfp-00007/series/results/search?format=atom&uid=D1A2BC737286408D4982D4096CA8DA1D63CB3F5E\",\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(row):\n",
    "    search = ciop.search(end_point=row['catalogue_url'], \n",
    "                                  params=[],\n",
    "                                  output_fields='self,enclosure,startdate,enddate,wkt,updated',\n",
    "                                  model='GeoTime')[0]\n",
    "    \n",
    "    series = pd.Series(search)\n",
    "    \n",
    "    series['startdate'] = pd.to_datetime(series['startdate'])\n",
    "    series['enddate'] = pd.to_datetime(series['enddate'])\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosure</th>\n",
       "      <th>enddate</th>\n",
       "      <th>self</th>\n",
       "      <th>startdate</th>\n",
       "      <th>updated</th>\n",
       "      <th>wkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-04-11T16:51:44.8941880+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-04-11T16:51:44.8941880+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-04-11T16:51:44.8941890+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2019-04-11T16:50:37.4658440+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2019-04-11T16:50:37.4658440+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2019-04-11T16:50:37.4658450+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2019-04-11T16:49:36.9113950+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2019-04-11T16:49:36.9113950+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://store.terradue.com/better-wfp-00007/_r...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>https://catalog.terradue.com//better-wfp-00007...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2019-04-11T16:49:36.9113940+00:00</td>\n",
       "      <td>POLYGON((11.5030755518998 -11.1141633706909,41...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enclosure    enddate  \\\n",
       "0  https://store.terradue.com/better-wfp-00007/_r... 2017-01-31   \n",
       "1  https://store.terradue.com/better-wfp-00007/_r... 2017-01-31   \n",
       "2  https://store.terradue.com/better-wfp-00007/_r... 2017-01-31   \n",
       "3  https://store.terradue.com/better-wfp-00007/_r... 2016-01-31   \n",
       "4  https://store.terradue.com/better-wfp-00007/_r... 2016-01-31   \n",
       "5  https://store.terradue.com/better-wfp-00007/_r... 2016-01-31   \n",
       "6  https://store.terradue.com/better-wfp-00007/_r... 2015-01-31   \n",
       "7  https://store.terradue.com/better-wfp-00007/_r... 2015-01-31   \n",
       "8  https://store.terradue.com/better-wfp-00007/_r... 2015-01-31   \n",
       "\n",
       "                                                self  startdate  \\\n",
       "0  https://catalog.terradue.com//better-wfp-00007... 2017-01-01   \n",
       "1  https://catalog.terradue.com//better-wfp-00007... 2017-01-01   \n",
       "2  https://catalog.terradue.com//better-wfp-00007... 2017-01-01   \n",
       "3  https://catalog.terradue.com//better-wfp-00007... 2016-01-01   \n",
       "4  https://catalog.terradue.com//better-wfp-00007... 2016-01-01   \n",
       "5  https://catalog.terradue.com//better-wfp-00007... 2016-01-01   \n",
       "6  https://catalog.terradue.com//better-wfp-00007... 2015-01-01   \n",
       "7  https://catalog.terradue.com//better-wfp-00007... 2015-01-01   \n",
       "8  https://catalog.terradue.com//better-wfp-00007... 2015-01-01   \n",
       "\n",
       "                             updated  \\\n",
       "0  2019-04-11T16:51:44.8941880+00:00   \n",
       "1  2019-04-11T16:51:44.8941880+00:00   \n",
       "2  2019-04-11T16:51:44.8941890+00:00   \n",
       "3  2019-04-11T16:50:37.4658440+00:00   \n",
       "4  2019-04-11T16:50:37.4658440+00:00   \n",
       "5  2019-04-11T16:50:37.4658450+00:00   \n",
       "6  2019-04-11T16:49:36.9113950+00:00   \n",
       "7  2019-04-11T16:49:36.9113950+00:00   \n",
       "8  2019-04-11T16:49:36.9113940+00:00   \n",
       "\n",
       "                                                 wkt  \n",
       "0  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "1  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "2  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "3  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "4  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "5  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "6  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "7  POLYGON((11.5030755518998 -11.1141633706909,41...  \n",
       "8  POLYGON((11.5030755518998 -11.1141633706909,41...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(input_references, str):\n",
    "    input_references = [input_references]\n",
    "\n",
    "gpd_data = GeoDataFrame(input_references, columns=['catalogue_url'])\n",
    "#gpd_data = GeoDataFrame(columns=['enclosure', 'start_date', 'end_date', 'product_type', 'aggregation', 'region'])\n",
    "gpd_data = gpd_data.apply(lambda row: get_info(row), axis=1)\n",
    "\n",
    "\n",
    "'''for i, enc in enumerate(gpd_data['enclosure'].tolist()):\n",
    "    print(i)\n",
    "    print(enc)\n",
    "    filename = os.path.splitext(os.path.basename(enc))[0]\n",
    "    file_comp = filename.split('_')\n",
    "    start_date = file_comp[-2]\n",
    "    end_date = file_comp[-1]\n",
    "    product_type = file_comp[0]\n",
    "    region = file_comp[1]\n",
    "    aggregation = file_comp[3]'''\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "gpd_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product(url, dest):\n",
    "    \n",
    "    #request_headers = {'X-JFrog-Art-Api': api_key}\n",
    "\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    open(dest, 'wb').write(r.content)\n",
    "    \n",
    "    return r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_date(product_reference):\n",
    "    metadata = ciop.search(end_point=product_reference,\n",
    "                           params=[],\n",
    "                           output_fields='identifier,startdate,enddate',\n",
    "                           model=\"GeoTime\")\n",
    "    return metadata[0]['startdate'], metadata[0]['enddate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_match_duplicates(gdf_match):\n",
    "    years = gdf_match['startdate'].dt.year.unique()\n",
    "    for year in years:\n",
    "        products = gdf_match[gdf_match['startdate'].dt.year == year]\n",
    "        if len(products.index.values) > 1:\n",
    "            outdated_indexes = products[products['updated'] != max(products['updated'])].index.values\n",
    "            gdf_match = gdf_match.drop(outdated_indexes)\n",
    "    return gdf_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_properties_file(dataframe, output_name):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    first_date = get_formatted_date(dataframe.iloc[0]['self'])[0]\n",
    "    last_date = get_formatted_date(dataframe.iloc[-1]['self'])[1]\n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (dataframe.iloc[0]['wkt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lta(dataframe):\n",
    "    file_list = []\n",
    "    if not os.path.isdir('tmp_data'):\n",
    "        os.mkdir('tmp_data')\n",
    "    for enclosure in dataframe['enclosure'].tolist():\n",
    "        filepath = 'tmp_data/' + os.path.basename(enclosure)\n",
    "        status = get_product(enclosure, filepath)\n",
    "        if status == 200:\n",
    "            file_list.append(filepath)\n",
    "    print(file_list)\n",
    "    if file_list:\n",
    "        n_years = len(file_list)\n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        print('Aggregations converted to matrices')\n",
    "        lta = calc_average(agr_period_matrix, n_years)\n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        for file_ in file_list:\n",
    "            os.remove(file_)\n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(lta, period_start_date, period_end_date, product_type, period_N, agr_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    start_day_month = str(period_start_date.month) + '-' + str(period_start_date.day)\n",
    "    end_day_month = str(period_end_date.month) + '-' + str(period_end_date.day)\n",
    "    output_name = 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + start_day_month + '_' + end_day_month + '_' + str(period_start_date.year) + '_' + str(period_end_date.year) + '.tif'\n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "['tmp_data/CHIRPSv2_SouthernAfrica_N30_daystotal_2015-01-01_2015-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_daystotal_2016-01-01_2016-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_daystotal_2017-01-01_2017-01-31.tif']\n",
      "Aggregations converted to matrices\n",
      "LTA_CHIRPSv2_SouthernAfrica_N30_daystotal_1-1_1-31_2015_2017.tif\n",
      "3\n",
      "3\n",
      "['tmp_data/CHIRPSv2_SouthernAfrica_N30_countaboveone_2015-01-01_2015-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_countaboveone_2016-01-01_2016-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_countaboveone_2017-01-01_2017-01-31.tif']\n",
      "Aggregations converted to matrices\n",
      "LTA_CHIRPSv2_SouthernAfrica_N30_countaboveone_1-1_1-31_2015_2017.tif\n",
      "3\n",
      "3\n",
      "['tmp_data/CHIRPSv2_SouthernAfrica_N30_dryspell_2015-01-01_2015-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_dryspell_2016-01-01_2016-01-31.tif', 'tmp_data/CHIRPSv2_SouthernAfrica_N30_dryspell_2017-01-01_2017-01-31.tif']\n",
      "Aggregations converted to matrices\n",
      "LTA_CHIRPSv2_SouthernAfrica_N30_dryspell_1-1_1-31_2015_2017.tif\n"
     ]
    }
   ],
   "source": [
    "gpd_data = gpd_data.sort_values(by='startdate')\n",
    "while not gpd_data.empty:\n",
    "    l1 = gpd_data.iloc[0]\n",
    "    filename = os.path.splitext(os.path.basename(l1['enclosure']))[0].split('_')\n",
    "    agr = filename[3]\n",
    "    prod_type = filename[0]\n",
    "    N_value = filename[2]\n",
    "    region = filename[1]\n",
    "    match = gpd_data[(gpd_data['startdate'].dt.day == l1['startdate'].day) & \n",
    "                     (gpd_data['startdate'].dt.month == l1['startdate'].month) & \n",
    "                     (gpd_data['enddate'].dt.day == l1['enddate'].day) & \n",
    "                     (gpd_data['enddate'].dt.month == l1['enddate'].month) &\n",
    "                     (gpd_data['wkt'] == l1['wkt']) &\n",
    "                     (gpd_data['enclosure'].str.contains(agr)) &\n",
    "                     (gpd_data['enclosure'].str.contains(prod_type))]\n",
    "    \n",
    "    indexes = match.index.values\n",
    "    if len(indexes) > 1:\n",
    "        print(len(match.index.values))\n",
    "        match = remove_match_duplicates(match)\n",
    "        print(len(match.index.values))\n",
    "        lta, projection, geo_transform, no_data_value, data_type = calc_lta(match)\n",
    "        if lta is not None:\n",
    "            filename = write_output(lta, match.iloc[0]['startdate'], match.iloc[-1]['enddate'], prod_type, N_value, agr, region, projection, geo_transform, 'GTiff', no_data_value, data_type)\n",
    "            print(filename)\n",
    "            write_properties_file(match, filename)\n",
    "    gpd_data = gpd_data.drop(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nyear_agr = gpd_data[(gpd_data['start_date'].dt.year == first_year)]\\n\\nprint(year_agr)\\nfor i in range(len(year_agr)):\\n    start_date = year_agr.iloc[i]['start_date']\\n    end_date = year_agr.iloc[i]['end_date']\\n    start_day = start_date.day\\n    start_month = start_date.month\\n    end_day = end_date.day\\n    end_month = end_date.month\\n    product_enclosure = year_agr.iloc[i]['enclosure'].split('_')\\n    product_type = product_enclosure[0]\\n    aggregation_type = product_enclosure[3]\\n    region = product_enclosure[1]\\n    agr_period = pd_data[(pd_data['start_date'].dt.day == start_day) & (pd_data['start_date'].dt.month == start_month) & \\n                         (pd_data['end_date'].dt.day == end_day) & (pd_data['end_date'].dt.month == end_month) & \\n                          pd_data['enclosure'].str.startswith(product_type) & pd_data['enclosure'].str.contains(aggregation_type) &\\n                          pd_data['enclosure'].str.contains(region)]\\n    agr_years = pd_data['start_date'].dt.year.unique()\\n    agr_period = agr_period['enclosure'].tolist()\\n    print(agr_period)\\n    n_years = len(agr_period)\\n    period_start = str(min(agr_years)) + '-' + str(start_month) + '-' + str(start_day)\\n    period_end = str(max(agr_years)) + '-' + str(end_month) + '-' + str(end_day)\\n    N = int(re.findall('N\\\\d{1,3}', agr_period[0])[0].split('N')[-1])\\n    try:\\n        agr_period_matrix = get_matrix_list(agr_period)\\n        print('Aggregations converted to matrices')\\n        print(agr_period_matrix[0])\\n        lta = calc_average(agr_period_matrix, n_years)\\n        print('LTA calculated successfully')\\n        print(lta)\\n        write_output(lta, period_start, period_end, product_type, N, aggregation_type, region, None, None, 'GTiff')\\n    except Exception as e:\\n        print('Error calculating Long-term Averages: ' + str(e))\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first_year = min(gpd_data['start_date'].dt.year.unique())\n",
    "\n",
    "'''\n",
    "\n",
    "year_agr = gpd_data[(gpd_data['start_date'].dt.year == first_year)]\n",
    "\n",
    "print(year_agr)\n",
    "for i in range(len(year_agr)):\n",
    "    start_date = year_agr.iloc[i]['start_date']\n",
    "    end_date = year_agr.iloc[i]['end_date']\n",
    "    start_day = start_date.day\n",
    "    start_month = start_date.month\n",
    "    end_day = end_date.day\n",
    "    end_month = end_date.month\n",
    "    product_enclosure = year_agr.iloc[i]['enclosure'].split('_')\n",
    "    product_type = product_enclosure[0]\n",
    "    aggregation_type = product_enclosure[3]\n",
    "    region = product_enclosure[1]\n",
    "    agr_period = pd_data[(pd_data['start_date'].dt.day == start_day) & (pd_data['start_date'].dt.month == start_month) & \n",
    "                         (pd_data['end_date'].dt.day == end_day) & (pd_data['end_date'].dt.month == end_month) & \n",
    "                          pd_data['enclosure'].str.startswith(product_type) & pd_data['enclosure'].str.contains(aggregation_type) &\n",
    "                          pd_data['enclosure'].str.contains(region)]\n",
    "    agr_years = pd_data['start_date'].dt.year.unique()\n",
    "    agr_period = agr_period['enclosure'].tolist()\n",
    "    print(agr_period)\n",
    "    n_years = len(agr_period)\n",
    "    period_start = str(min(agr_years)) + '-' + str(start_month) + '-' + str(start_day)\n",
    "    period_end = str(max(agr_years)) + '-' + str(end_month) + '-' + str(end_day)\n",
    "    N = int(re.findall('N\\d{1,3}', agr_period[0])[0].split('N')[-1])\n",
    "    try:\n",
    "        agr_period_matrix = get_matrix_list(agr_period)\n",
    "        print('Aggregations converted to matrices')\n",
    "        print(agr_period_matrix[0])\n",
    "        lta = calc_average(agr_period_matrix, n_years)\n",
    "        print('LTA calculated successfully')\n",
    "        print(lta)\n",
    "        write_output(lta, period_start, period_end, product_type, N, aggregation_type, region, None, None, 'GTiff')\n",
    "    except Exception as e:\n",
    "        print('Error calculating Long-term Averages: ' + str(e))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
